digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139980725023184 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	139980725027360 [label=AddmmBackward0]
	139980725027456 -> 139980725027360
	139980724923824 [label="model.mlp.layers.2.bias
 (10)" fillcolor=lightblue]
	139980724923824 -> 139980725027456
	139980725027456 [label=AccumulateGrad]
	139980725027408 -> 139980725027360
	139980725027408 [label=ReluBackward0]
	139980725027264 -> 139980725027408
	139980725027264 [label=AddmmBackward0]
	139980725027600 -> 139980725027264
	139980724924224 [label="model.mlp.layers.0.bias
 (100)" fillcolor=lightblue]
	139980724924224 -> 139980725027600
	139980725027600 [label=AccumulateGrad]
	139980725027552 -> 139980725027264
	139980725027552 [label=ViewBackward0]
	139980725027696 -> 139980725027552
	139980725027696 [label=MaxPool2DWithIndicesBackward0]
	139980725027888 -> 139980725027696
	139980725027888 [label=ReluBackward0]
	139980725027984 -> 139980725027888
	139980725027984 [label=AddBackward0]
	139980725028080 -> 139980725027984
	139980725028080 [label=ThnnConv2DBackward0]
	139980725028224 -> 139980725028080
	139980725028224 [label=CloneBackward0]
	139980725028416 -> 139980725028224
	139980725028416 [label=MaxPool2DWithIndicesBackward0]
	139980725028512 -> 139980725028416
	139980725028512 [label=ReluBackward0]
	139980725028608 -> 139980725028512
	139980725028608 [label=AddBackward0]
	139980725028704 -> 139980725028608
	139980725028704 [label=ThnnConv2DBackward0]
	139980725028848 -> 139980725028704
	139980724923264 [label="model.feature_extractor.0.main_path.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	139980724923264 -> 139980725028848
	139980725028848 [label=AccumulateGrad]
	139980725028800 -> 139980725028704
	139980724923344 [label="model.feature_extractor.0.main_path.0.bias
 (32)" fillcolor=lightblue]
	139980724923344 -> 139980725028800
	139980725028800 [label=AccumulateGrad]
	139980725028656 -> 139980725028608
	139980725028656 [label=ThnnConv2DBackward0]
	139980725028944 -> 139980725028656
	139980724923504 [label="model.feature_extractor.0.shortcut_path.1.weight
 (32, 3, 1, 1)" fillcolor=lightblue]
	139980724923504 -> 139980725028944
	139980725028944 [label=AccumulateGrad]
	139980725028176 -> 139980725028080
	139980724923664 [label="model.feature_extractor.2.main_path.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139980724923664 -> 139980725028176
	139980725028176 [label=AccumulateGrad]
	139980725028128 -> 139980725028080
	139980724923744 [label="model.feature_extractor.2.main_path.0.bias
 (64)" fillcolor=lightblue]
	139980724923744 -> 139980725028128
	139980725028128 [label=AccumulateGrad]
	139980725028032 -> 139980725027984
	139980725028032 [label=ThnnConv2DBackward0]
	139980725028464 -> 139980725028032
	139980725028464 [label=CloneBackward0]
	139980725028416 -> 139980725028464
	139980725028368 -> 139980725028032
	139980724923904 [label="model.feature_extractor.2.shortcut_path.1.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	139980724923904 -> 139980725028368
	139980725028368 [label=AccumulateGrad]
	139980725027504 -> 139980725027264
	139980725027504 [label=TBackward0]
	139980725027936 -> 139980725027504
	139980724924144 [label="model.mlp.layers.0.weight
 (100, 4096)" fillcolor=lightblue]
	139980724924144 -> 139980725027936
	139980725027936 [label=AccumulateGrad]
	139980725027312 -> 139980725027360
	139980725027312 [label=TBackward0]
	139980725027840 -> 139980725027312
	139980724923984 [label="model.mlp.layers.2.weight
 (10, 100)" fillcolor=lightblue]
	139980724923984 -> 139980725027840
	139980725027840 [label=AccumulateGrad]
	139980725027360 -> 139980725023184
}
