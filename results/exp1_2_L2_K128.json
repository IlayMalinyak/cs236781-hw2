{
  "config": {
    "run_name": "exp1_2",
    "out_dir": "./results",
    "seed": 42,
    "device": null,
    "bs_train": 128,
    "bs_test": 32,
    "batches": 100,
    "epochs": 100,
    "early_stopping": 5,
    "checkpoints": null,
    "lr": 0.003007970289449718,
    "reg": 0.008128033924872312,
    "filters_per_layer": [
      128
    ],
    "layers_per_block": 2,
    "pool_every": 1,
    "hidden_dims": [
      512,
      512
    ],
    "model_type": "cnn",
    "activation_type": "relu",
    "activation_params": {},
    "pooling_type": "max",
    "pooling_params": {
      "kernel_size": 2
    },
    "batchnorm": true,
    "dropout": 0.1633292046324038,
    "bottleneck": false,
    "loss_fn": "cross entropy",
    "optimizer": "Adam",
    "hp_optim": {
      "betas": [
        0.9969682475071221,
        0.9835809796844466
      ]
    },
    "subset": false
  },
  "results": {
    "num_epochs": 15,
    "train_loss": [
      1.6329051759236914,
      1.3357983946495349,
      1.2035233639085385,
      1.0984390713369754,
      1.0396696989188718,
      0.9724687525378469,
      0.9419634560185015,
      0.9059249598656773,
      0.904087935567207,
      0.8827771910316194,
      0.8918065366232791,
      0.8766680468073891,
      0.8653835974385976,
      0.8698974430103741,
      0.8769375802305959
    ],
    "train_acc": [
      40.642,
      51.68,
      57.076,
      60.692,
      63.322,
      65.77,
      66.716,
      68.038,
      68.134,
      69.102,
      68.596,
      69.086,
      69.608,
      69.46,
      69.228
    ],
    "test_loss": [
      1.3955352313983174,
      1.2596006218236857,
      1.1793806813776302,
      1.1110131812933535,
      1.0742636273463313,
      1.0524586871409187,
      0.999504701207621,
      1.0383492016944642,
      0.9679574943579043,
      0.9792000432364857,
      0.9878951591043807,
      0.9853569615763217,
      0.9655357613540686,
      1.0425147848388256,
      0.9954675171321954
    ],
    "test_acc": [
      49.6,
      54.48,
      57.9,
      60.73,
      62.44,
      62.24,
      65.1,
      64.08,
      65.78,
      65.92,
      64.72,
      65.68,
      65.88,
      64.13,
      65.32
    ]
  }
}